log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Target=System.out
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d{HH:mm:ss,SSS} [%-21c] %5p %m%n

log4j.appender.rfout=org.apache.log4j.DailyRollingFileAppender
log4j.appender.rfout.File=${marmot.home}/logs/marmot.log
log4j.appender.rfout.ImmediateFlush=true
log4j.appender.rfout.Threshold=true
log4j.appender.rfout.DatePattern=.yyyy-MM-dd
log4j.appender.rfout.layout=org.apache.log4j.PatternLayout
log4j.appender.rfout.layout.ConversionPattern=%d{HH:mm:ss,SSS} [%-21c{3}] %5p %m%n

log4j.appender.sock=org.apache.log4j.net.SocketAppender
log4j.appender.sock.remoteHost=210.91.246.190
log4j.appender.sock.port=4445
log4j.appender.sock.locationInfo=true
log4j.appender.sock.layout=org.apache.log4j.xml.XMLLayout

#log4j.rootLogger=warn, rfout
log4j.rootLogger=info, stdout
#log4j.rootLogger=debug, sock

log4j.logger.org.apache.hadoop=warn
log4j.logger.org.apache.hadoop.util.NativeCodeLoader=error

# Apache Spark relateds
log4j.logger.org.apache.spark=info
log4j.logger.org.apache.spark.ui=warn
log4j.logger.org.apache.spark.SparkEnv=warn
log4j.logger.org.apache.spark.SecurityManager=warn
log4j.logger.org.apache.spark.MapOutputTrackerMasterEndpoint=warn
log4j.logger.org.apache.spark.SparkContext=warn
log4j.logger.org.apache.spark.executor=warn
#log4j.logger.org.apache.spark.sql=warn
log4j.logger.org.apache.spark.sql.execution.aggregate=warn
log4j.logger.org.apache.spark.sql.execution.datasources=warn
log4j.logger.org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol=warn
log4j.logger.org.apache.spark.sql.execution.datasources.FileFormatWriter=warn
log4j.logger.org.apache.spark.sql.execution.datasources.parquet=warn
log4j.logger.org.apache.spark.sql.execution.datasources.FileScanRDD=warn
log4j.logger.org.apache.spark.sql.execution.FileSourceScanExec=warn
log4j.logger.org.apache.spark.sql.catalyst=warn
log4j.logger.org.apache.spark.sql.internal=warn
log4j.logger.org.apache.spark.sql.hive=warn
log4j.logger.org.apache.spark.scheduler=warn
log4j.logger.org.apache.spark.storage=warn
log4j.logger.org.apache.spark.util=warn
log4j.logger.org.apache.spark.resource=warn
log4j.logger.org.apache.spark.network=warn
log4j.logger.org.apache.spark.mapred=warn
log4j.logger.org.apache.spark.hive=warn
log4j.logger.org.apache.spark.deploy.yarn=warn
#log4j.logger.org.apache.parquet=warn

log4j.logger.org.apache.hadoop.hive=warn
log4j.logger.org.apache.hadoop.hive.metastore.ObjectStore=error
log4j.logger.org.apache.hadoop.hive.conf=error
log4j.logger.org.apache.hadoop.hive.ql=error
log4j.logger.hive=warn
log4j.logger.org.sparkproject=warn

log4j.logger.DataNucleus=warn

#log4j.logger.jarvey.datasource.shp=debug

# Apache Parquet
log4j.logger.org.apache.parquet=warn
